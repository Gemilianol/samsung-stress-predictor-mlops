{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062716c6",
   "metadata": {},
   "source": [
    "# üìÅ 01 - Data Handling\n",
    "\n",
    "### üéØ Objective\n",
    "This notebook is responsible for loading, cleaning, and merging the raw CSV data exported from my personal **Samsung Health‚Ñ¢** account. The result is a single, unified dataset ready for downstream time series processing and machine learning tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### üíª Devices Used\n",
    "- **Samsung Galaxy Note 9** (Until July 2022)  \n",
    "- **Samsung Galaxy S22 Ultra + Samsung Watch 4 Classic** (After July 2022)\n",
    "\n",
    "> **Samsung is a registered trademark of Samsung Electronics Co., Ltd.**  \n",
    "> This project is for personal and educational purposes only.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Key Steps\n",
    "\n",
    "1. **Load Raw Files**  \n",
    "   Import all CSVs exported from Samsung Health ‚Äî each containing data from different modalities (nutrition, exercise, sleep, stress, etc.).\n",
    "\n",
    "2. **Clean Columns**  \n",
    "   - Remove unnecessary rows (e.g., metadata or malformed headers)  \n",
    "   - Rename and standardize column names and formats  \n",
    "   - Convert datatypes as needed\n",
    "\n",
    "3. **Initial Checks**  \n",
    "   - Explore missing values  \n",
    "   - Identify inconsistent date ranges or sparsity\n",
    "\n",
    "4. **Merge Datasets**  \n",
    "   Join all dataframes on the `date` column, ensuring features are aligned chronologically.\n",
    "\n",
    "5. **Save Intermediate Output**  \n",
    "   Export the merged, lightly cleaned dataset to `data.csv`, for reuse in subsequent notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Output\n",
    "- `data.csv`: Unified daily time series dataset with features from most of the health modalities.\n",
    "\n",
    "---\n",
    "\n",
    "> üìù **Note**: This notebook performs only structural and light cleaning. Full feature engineering and normalization are handled in later steps of the pipeline.\n",
    "> ‚ö†Ô∏è **Note on Data Availability**:\n",
    "The quantity and type of variables available may vary depending on your devices and how they are set up. You might need to adapt parts of this project to match the structure and availability of your own Samsung Health data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3dc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 1000) #Display all the columns.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chardet for Character detection\n",
    "\n",
    "# File name format:\n",
    "# - %Y%m%d means date in format like 01012025\n",
    "# - XXXXXX I think it's like a personal ID so check it on your files.\n",
    "\n",
    "# with open(\"../data/raw/com.samsung.health.floors_climbed.%Y%m%dXXXXXX.csv\", \"rb\") as f:\n",
    "#     raw = f.read(10000)\n",
    "#     result = chardet.detect(raw)\n",
    "#     print(result)\n",
    "#     #{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''} <= Compatible with latin-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4829c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "floors = pd.read_csv(\"../data/raw/com.samsung.health.floors_climbed.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1, #Avoid the first row of the file. \n",
    "                        index_col=False, # Force pandas to not use the first column as the index.\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte.\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN.\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "floors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "floors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddd67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll keep only one date for reference and future data mergings.\n",
    "floors.drop(columns=['custom', 'update_time', 'create_time', 'client_data_id',\n",
    "       'client_data_ver','raw_data', 'time_offset', 'deviceuuid',\n",
    "       'pkg_name', 'end_time','datauuid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "floors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287746d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll format the date as day format:\n",
    "floors['start_time'] = pd.to_datetime(floors['start_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "floors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea is that, keep a row per day so:\n",
    "floors = floors.groupby('start_time')['floor'].sum().reset_index()\n",
    "#IMPORTANT: groupby returns DataFrameGroupBy. After applying an aggregation functions (like sum()) returns a pandasSeries. \n",
    "# Only applying reset_index you finally get a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04176d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "floors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns for future clarity:\n",
    "floors.columns = ['date', 'total_floors_climbed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df15148",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadece6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info = pd.read_csv(\"../data/raw/com.samsung.health.food_info.%Y%m%dXXXXXX.csv\", \n",
    "                        sep=\",\",\n",
    "                        header=1, # Python index from zero so avoid the first row and take the second one as header.\n",
    "                        index_col=False, # Force pandas to not use the first column as the index.\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte.\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN.\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f071cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1619bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cf1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the values are 0.0 perhaps because this feature \n",
    "# it's not informed by the food industry so we need to remove it:\n",
    "food_info['added_sugar'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.drop(columns=['custom', 'provider_food_id',\n",
    "                        'update_time',\n",
    "                        'serving_description',\n",
    "                        'info_provider', 'deviceuuid',\n",
    "                        'metric_serving_unit',\n",
    "                        'pkg_name', 'unit_count_per_calorie',\n",
    "                        'default_number_of_serving_unit','description',\n",
    "                        'metric_serving_amount', 'name',\n",
    "                        'added_sugar', 'datauuid'\n",
    "                        ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info['create_time'] = pd.to_datetime(food_info['create_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96dddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2941d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps this feature it's not useful at all neither (Fully of 0.0 values)\n",
    "food_info['vitamin_d'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728335d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.drop(columns='vitamin_d', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can keep:\n",
    "food_info['trans_fat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92020e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info = food_info.groupby('create_time').sum().reset_index()\n",
    "food_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4464420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here again, renaming the columns for future clarity:\n",
    "food_info.columns = ['date', 'potassium', 'vitamin_a', 'vitamin_c', 'cholesterol',\n",
    "       'sodium', 'dietary_fiber', 'total_fat', 'monosaturated_fat', 'protein',\n",
    "       'polysaturated_fat', 'iron', 'sugar', 'calcium', 'ingested_calories',\n",
    "       'saturated_fat', 'trans_fat', 'carbohydrate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f2ff0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b35860",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = pd.read_csv(\"../data/raw/com.samsung.health.weight.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1,\n",
    "                        index_col=False, # Force pandas to not use the first column as the index\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b21fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6333bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.drop(columns=['create_sh_ver', 'custom','modify_sh_ver', \n",
    "                     'update_time', 'create_time','client_data_id',\n",
    "                     'client_data_ver','deviceuuid', 'time_offset',\n",
    "                     'comment','pkg_name','vfa_level','datauuid'], \n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ba5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight['start_time'] = pd.to_datetime(weight['start_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ace381",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96754c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d041d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature will be removed:\n",
    "weight['muscle_mass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0dd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.drop(columns='muscle_mass', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c38756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one we can keep it:\n",
    "weight['skeletal_muscle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column renaming:\n",
    "weight.columns = ['body_fat_mass', 'date', 'height', 'weight', 'skeletal_muscle',\n",
    "       'fat_free_mass', 'basal_metabolic_rate', 'skeletal_muscle_mass',\n",
    "       'fat_free', 'body_fat', 'total_body_water']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ebb2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv(\"../data/raw/com.samsung.shealth.activity.day_summary.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1,\n",
    "                        index_col=False, # Force pandas to not use the first column as the index\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5505db",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6bd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.drop(columns=['create_sh_ver', 'energy_type', 'exercise_time',\n",
    "                        'exercise_calorie_target', 'active_time', 'target',\n",
    "                        'others_time', 'modify_sh_ver','update_time','floors_target',\n",
    "                        'create_time', 'floor_count', 'dynamic_active_time_target',\n",
    "                        'exercise_time_target', 'goal', 'longest_active_time',\n",
    "                         'move_hourly_count', 'duration_type', 'move_hourly_target', 'distance',\n",
    "                        'dynamic_active_time','extra_data', 'deviceuuid',\n",
    "                        'run_time', 'pkg_name', 'walk_time', 'longest_idle_time','datauuid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2184d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity['day_time']=pd.to_datetime(activity['day_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e73cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = activity.groupby('day_time').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235070f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283394f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1134324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature need to be removed (All values equal to 0.0):\n",
    "activity['movement_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.drop(columns='movement_type', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08933f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns:\n",
    "activity.columns = ['date', 'step_count', 'score', 'total_steps_burned_calories']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca342d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned =  pd.read_csv(\"../data/raw/com.samsung.shealth.calories_burned.details.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1,\n",
    "                        index_col=False, # Force pandas to not use the first column as the index\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fba03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned.drop(columns=['active_calories_goal', 'version', 'extra_data', 'exercise_calories',\n",
    "                     'com.samsung.shealth.calories_burned.create_sh_ver',\n",
    "                    'com.samsung.shealth.calories_burned.modify_sh_ver',\n",
    "                    'com.samsung.shealth.calories_burned.update_time',\n",
    "                    'com.samsung.shealth.calories_burned.active_calorie',\n",
    "                    'com.samsung.shealth.calories_burned.deviceuuid',\n",
    "                    'com.samsung.shealth.calories_burned.pkg_name',\n",
    "                    'com.samsung.shealth.calories_burned.day_time',\n",
    "                    'com.samsung.shealth.calories_burned.datauuid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned['com.samsung.shealth.calories_burned.create_time'] = pd.to_datetime(burned['com.samsung.shealth.calories_burned.create_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9942408",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a521f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned.columns = ['total_excercise_calories', 'burned_tef_calories', 'burned_active_time',\n",
    "                  'burned_rest_calories', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28695be8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep =  pd.read_csv(\"../data/raw/com.samsung.shealth.sleep_combined.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1,\n",
    "                        index_col=False, # Force pandas to not use the first column as the index\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1956d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the feature column to see if it's a real NaN feature or not at all. \n",
    "sleep['latency_weight'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.drop(columns=['total_sleep_time_weight', 'original_efficiency', 'create_sh_ver',\n",
    "       'start_time','wake_score', 'deep_score', 'latency_weight',\n",
    "       'has_sleep_data', 'sleep_efficiency_with_latency','total_rem_duration',\n",
    "       'modify_sh_ver', 'update_time', 'create_time', 'client_data_id',\n",
    "       'sleep_type', 'data_version', 'latency_score', 'deep_weight',\n",
    "       'rem_weight','original_wake_up_time',\n",
    "       'client_data_ver','original_bed_time',\n",
    "       'goal_bed_time', 'quality', 'time_offset', 'extra_data', 'wake_weight',\n",
    "       'deviceuuid', 'rem_score', 'goal_wake_up_time', 'sleep_cycle','pkg_name',\n",
    "        'stage_analyzed_type','stage_analysis_type', 'total_sleep_time_score','datauuid',\n",
    "        ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature must be removed:\n",
    "sleep['factor_10'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.drop(columns='factor_10', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2adf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep['end_time'] = pd.to_datetime(sleep['end_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c89417",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep = sleep.add_prefix('sleep_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14aba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep.columns = ['sleep_mental_recovery', 'sleep_factor_01', 'sleep_factor_02',\n",
    "       'sleep_factor_03', 'sleep_factor_04', 'sleep_factor_05',\n",
    "       'sleep_factor_06', 'sleep_factor_07', 'sleep_factor_08',\n",
    "       'sleep_factor_09', 'sleep_physical_recovery',\n",
    "       'sleep_movement_awakening', 'sleep_total_light_duration',\n",
    "       'sleep_efficiency', 'sleep_sleep_score', 'sleep_sleep_duration',\n",
    "       'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835620c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d2ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress =  pd.read_csv(\"../data/raw/com.samsung.shealth.stress.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1,\n",
    "                        index_col=False, # Force pandas to not use the first column as the index\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.drop(columns=['create_sh_ver', 'start_time', 'custom', 'binning_data', \n",
    "                     'tag_id','modify_sh_ver', 'update_time', 'create_time', \n",
    "                     'algorithm', 'time_offset', 'deviceuuid', 'comment', \n",
    "                     'pkg_name','datauuid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress['end_time'] = pd.to_datetime(stress['end_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d289ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to add a prefix or suffix to every column name, \n",
    "# you can use the add_prefix() and add_suffix() methods. \n",
    "# These methods are helpful when you need to modify all column names in a consistent way.\n",
    "stress = stress.add_prefix('stress_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97926e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = stress.groupby('stress_end_time').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d36571",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d72949",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = stress.rename(columns={'stress_end_time': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99894c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart =  pd.read_csv(\"../data/raw/com.samsung.shealth.tracker.heart_rate.%Y%m%dXXXXXX.csv\",\n",
    "                        sep=\",\",\n",
    "                        header=1,\n",
    "                        index_col=False, # Force pandas to not use the first column as the index\n",
    "                        encoding=\"latin-1\", #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 28: invalid continuation byte\n",
    "                        na_values=[\"\", \" \", \"NaN\", \"nan\"], # Additional strings to recognize as NA/NaN\n",
    "                        keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb91794",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.drop(columns=['source', 'tag_id', 'com.samsung.health.heart_rate.create_sh_ver',\n",
    "       'com.samsung.health.heart_rate.heart_beat_count',\n",
    "       'com.samsung.health.heart_rate.start_time',\n",
    "       'com.samsung.health.heart_rate.custom',\n",
    "       'com.samsung.health.heart_rate.binning_data',\n",
    "       'com.samsung.health.heart_rate.modify_sh_ver',\n",
    "       'com.samsung.health.heart_rate.update_time',\n",
    "       'com.samsung.health.heart_rate.create_time',\n",
    "       'com.samsung.health.heart_rate.client_data_id',\n",
    "        'com.samsung.health.heart_rate.client_data_ver',\n",
    "       'com.samsung.health.heart_rate.time_offset',\n",
    "       'com.samsung.health.heart_rate.deviceuuid',\n",
    "       'com.samsung.health.heart_rate.comment',\n",
    "       'com.samsung.health.heart_rate.pkg_name',\n",
    "       'com.samsung.health.heart_rate.datauuid'\n",
    "       ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart['com.samsung.health.heart_rate.end_time'] = pd.to_datetime(heart['com.samsung.health.heart_rate.end_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6093778",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420852ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a130580",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ea593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sort by time (VERY IMPORTANT)\n",
    "heart = heart.sort_index()\n",
    "\n",
    "# 3. Impute NaNs with the previous valid value\n",
    "heart = heart.bfill().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b59335",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b65f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I need to take the max, min and the median value of the heart rate for each date:\n",
    "df1 = heart.groupby('com.samsung.health.heart_rate.end_time')['com.samsung.health.heart_rate.max'].max().reset_index()\n",
    "df2 = heart.groupby('com.samsung.health.heart_rate.end_time')['com.samsung.health.heart_rate.min'].min().reset_index()\n",
    "df3 = heart.groupby('com.samsung.health.heart_rate.end_time')['com.samsung.health.heart_rate.heart_rate'].median().reset_index()\n",
    "\n",
    "heart = pd.merge(df1, df2, on='com.samsung.health.heart_rate.end_time', how='outer') # Use 'outer' to keep all dates\n",
    "heart = pd.merge(heart, df3, on='com.samsung.health.heart_rate.end_time', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d210fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.columns = ['date', 'heart_max_rate', 'heart_min_rate','heart_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf49c4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(floors, food_info, on='date', how='outer')\n",
    "data = pd.merge(data, weight, on='date', how='outer')\n",
    "data = pd.merge(data, activity, on='date', how='outer')\n",
    "data = pd.merge(data, burned, on='date', how='outer')\n",
    "data = pd.merge(data, sleep, on='date', how='outer')\n",
    "data = pd.merge(data, stress, on='date', how='outer')\n",
    "data = pd.merge(data, heart, on='date', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2336069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43759f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for date duplicates just in case:\n",
    "data.duplicated(subset='date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b11f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .sum() it's the most straightforward but perhaps it's not suitable if the duplicates comes from weight, stress or heart rate.\n",
    "# In this cases will be better take the mean or median instead.\n",
    "# Check your case before apply it. \n",
    "data = data.groupby('date').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d870a5",
   "metadata": {},
   "source": [
    "#### Imputation Process\n",
    "##### We will try to do it with rationality and common sense in order to avoid lose a lot of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d012ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On body composition, I'll assume that, the last state is the same as the previews so:\n",
    "cols = ['body_fat_mass', 'height', 'weight', 'skeletal_muscle', 'fat_free_mass',\n",
    "       'basal_metabolic_rate', 'skeletal_muscle_mass', 'fat_free', 'body_fat',\n",
    "       'total_body_water']\n",
    "\n",
    "#Here first need to convert the zero coerced values to NaN in order to then back fill them.\n",
    "data[cols] = data[cols].replace(0.0, np.nan)\n",
    "\n",
    "data[cols] = data[cols].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps imputation. Strictly rationality so:\n",
    "cols = ['burned_tef_calories', 'burned_active_time','burned_rest_calories']\n",
    "\n",
    "data[cols] = data[cols].replace(0.0, np.nan)\n",
    "\n",
    "#These features I think are independents of the steps so:\n",
    "data[cols] = data[cols].fillna(value=data[cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bae9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I think the NaN was generate by the watch during my sleeping time so I'll asumme that was similar to the last record:\n",
    "cols = ['sleep_mental_recovery', 'sleep_factor_01',\n",
    "       'sleep_factor_02', 'sleep_factor_03', 'sleep_factor_04',\n",
    "       'sleep_factor_05', 'sleep_factor_06', 'sleep_factor_07',\n",
    "       'sleep_factor_08', 'sleep_factor_09', 'sleep_physical_recovery',\n",
    "       'sleep_movement_awakening', 'sleep_total_light_duration',\n",
    "       'sleep_efficiency', 'sleep_sleep_score', 'sleep_sleep_duration']\n",
    "\n",
    "data[cols] = data[cols].replace(0.0, np.nan)\n",
    "\n",
    "data[cols] = data[cols].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e33be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for stress and heart rate:\n",
    "cols = ['stress_max', 'stress_min', 'stress_score', 'heart_max_rate',\n",
    "       'heart_min_rate', 'heart_rate']\n",
    "\n",
    "data[cols] = data[cols].replace(0.0, np.nan)\n",
    "\n",
    "data[cols] = data[cols].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to trim the dataset from July 3rd 2022 in order to eliminate the bad backward fill imputation.\n",
    "data['date'] = data['date'].astype('str')\n",
    "data[data['date'] > '2022-07-01']['stress_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[571:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This starting file will be use in EDA file in order to analyze:\n",
    "data.to_csv('../data/processed/data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
